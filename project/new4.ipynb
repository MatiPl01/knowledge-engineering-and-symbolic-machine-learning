{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep01  train 0.599/0.574  test 0.746/0.583\n",
      "ep02  train 0.733/0.725  test 0.822/0.713\n",
      "ep03  train 0.795/0.786  test 0.875/0.765\n",
      "ep04  train 0.818/0.810  test 0.865/0.760\n",
      "ep05  train 0.828/0.821  test 0.858/0.760\n",
      "ep06  train 0.851/0.846  test 0.787/0.702\n",
      "ep07  train 0.864/0.859  test 0.857/0.763\n",
      "ep08  train 0.871/0.867  test 0.814/0.720\n",
      "ep09  train 0.893/0.890  test 0.718/0.643\n",
      "ep10  train 0.901/0.898  test 0.887/0.789\n",
      "ep11  train 0.917/0.915  test 0.831/0.738\n",
      "ep12  train 0.927/0.926  test 0.795/0.704\n",
      "ep13  train 0.937/0.936  test 0.809/0.716\n",
      "ep14  train 0.946/0.945  test 0.741/0.663\n",
      "ep15  train 0.944/0.943  test 0.842/0.742\n",
      "ep16  train 0.963/0.962  test 0.798/0.703\n",
      "ep17  train 0.963/0.963  test 0.820/0.726\n",
      "ep18  train 0.964/0.964  test 0.834/0.737\n",
      "ep19  train 0.967/0.967  test 0.824/0.727\n",
      "ep20  train 0.972/0.971  test 0.824/0.729\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Stable end-to-end pipeline:  WAV → log-Mel → global-norm → CRNN\n",
    "----------------------------------------------------------------\n",
    "• Works with librosa ≥ 0.10\n",
    "• No warnings, no –inf / +inf, no OverflowError (silent clips OK)\n",
    "• Folder layout:\n",
    "      cleaned_dataset/\n",
    "          train/{questions,others}/*.wav\n",
    "          test/{questions,others}/*.wav\n",
    "----------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "import os, random, warnings, math, numpy as np, torch, librosa\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import torch.nn as nn\n",
    "\n",
    "# ─── hyper-params & reproducibility ──────────────────────────────────────\n",
    "ROOT = Path(\"cleaned_dataset\")\n",
    "SR = 16_000  # resample rate\n",
    "N_FFT = 1024\n",
    "HOP = 256\n",
    "N_MELS = 128\n",
    "TOP_DB = 80.0  # dynamic-range clamp (dB)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "LR = 1e-3\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "\n",
    "# ─── robust helpers ──────────────────────────────────────────────────────\n",
    "def safe_load(path: Path) -> np.ndarray:\n",
    "    \"\"\"Return mono float32 signal (guaranteed non-empty).\"\"\"\n",
    "    y, _ = librosa.load(str(path), sr=SR, mono=True)\n",
    "    if y.size == 0:\n",
    "        y = np.zeros(int(0.1 * SR), dtype=np.float32)  # 100 ms silence\n",
    "    return y.astype(np.float32)\n",
    "\n",
    "\n",
    "def log_mel(y: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Waveform → log-Mel in dB (shape = [n_mels, T]) – finite values only.\"\"\"\n",
    "    if y.size < N_FFT:\n",
    "        y = np.pad(y, (0, N_FFT - y.size), mode=\"constant\")\n",
    "    S = librosa.feature.melspectrogram(\n",
    "        y=y, sr=SR, n_fft=N_FFT, hop_length=HOP, n_mels=N_MELS, power=2.0, center=True\n",
    "    )\n",
    "    # Avoid log(0) and clamp dynamic range\n",
    "    S_db = librosa.power_to_db(S, ref=np.max, amin=1e-10, top_db=TOP_DB)\n",
    "    S_db = np.nan_to_num(S_db, neginf=-TOP_DB, posinf=0.0)\n",
    "    return S_db.astype(np.float32)\n",
    "\n",
    "\n",
    "# ─── dataset & dataloader ────────────────────────────────────────────────\n",
    "def list_wavs(split: str):\n",
    "    base = ROOT / split\n",
    "    pairs = [(p, 0) for p in (base / \"others\").rglob(\"*.wav\")]\n",
    "    pairs += [(p, 1) for p in (base / \"questions\").rglob(\"*.wav\")]\n",
    "    random.shuffle(pairs)\n",
    "    return pairs\n",
    "\n",
    "\n",
    "def compute_global_cmvn(paths):\n",
    "    \"\"\"Return mean, std over *all* frames in training set.\"\"\"\n",
    "    sum_, sq_sum, count = 0.0, 0.0, 0\n",
    "    for p, _ in paths:\n",
    "        m = log_mel(safe_load(p))\n",
    "        sum_ += m.sum()\n",
    "        sq_sum += (m**2).sum()\n",
    "        count += m.size\n",
    "    mean = sum_ / count\n",
    "    std = math.sqrt(sq_sum / count - mean**2 + 1e-12)\n",
    "    return mean, std\n",
    "\n",
    "\n",
    "class MelDataset(Dataset):\n",
    "    def __init__(self, file_label_pairs, mean, std):\n",
    "        self.items, self.mean, self.std = file_label_pairs, mean, std\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.items[idx]\n",
    "        m = (log_mel(safe_load(path)) - self.mean) / (self.std + 1e-6)\n",
    "        return torch.from_numpy(m).unsqueeze(0), label  # (1, 128, T)\n",
    "\n",
    "\n",
    "def pad_collate(batch):\n",
    "    xs, ys = zip(*batch)\n",
    "    T_max = max(x.shape[-1] for x in xs)\n",
    "    padded = torch.zeros(len(xs), 1, N_MELS, T_max, dtype=torch.float32)\n",
    "    for i, x in enumerate(xs):\n",
    "        padded[i, :, :, : x.shape[-1]] = x\n",
    "    return padded, torch.tensor(ys)\n",
    "\n",
    "\n",
    "def get_loaders():\n",
    "    train_pairs, test_pairs = list_wavs(\"train\"), list_wavs(\"test\")\n",
    "    mean, std = compute_global_cmvn(train_pairs)\n",
    "    tr_ds = MelDataset(train_pairs, mean, std)\n",
    "    te_ds = MelDataset(test_pairs, mean, std)\n",
    "    tr_ld = DataLoader(\n",
    "        tr_ds, BATCH_SIZE, shuffle=True, collate_fn=pad_collate\n",
    "    )\n",
    "    te_ld = DataLoader(\n",
    "        te_ds, BATCH_SIZE, shuffle=False, collate_fn=pad_collate\n",
    "    )\n",
    "    return tr_ld, te_ld\n",
    "\n",
    "\n",
    "# ─── simple CRNN ─────────────────────────────────────────────────────────\n",
    "class CRNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 32, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.lstm = nn.LSTM(32 * (N_MELS // 4), 64, batch_first=True)\n",
    "        self.fc = nn.Linear(64, 2)\n",
    "\n",
    "    def forward(self, x):  # x: (B,1,128,T)\n",
    "        x = self.cnn(x)  # (B,32,32,T/4)   (128/4=32)\n",
    "        B, C, M, T = x.shape\n",
    "        x = x.permute(0, 3, 1, 2).reshape(B, T, C * M)  # (B,T,features)\n",
    "        h, _ = self.lstm(x)\n",
    "        return self.fc(h[:, -1])  # final time-step → logits\n",
    "\n",
    "\n",
    "# ─── training / evaluation ───────────────────────────────────────────────\n",
    "def run_epoch(model, loader, optim=None):\n",
    "    training = optim is not None\n",
    "    model.train() if training else model.eval()\n",
    "    y_true, y_pred, total_loss = [], [], 0.0\n",
    "    crit = nn.CrossEntropyLoss()\n",
    "    for X, y in loader:\n",
    "        X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "        out = model(X)\n",
    "        loss = crit(out, y)\n",
    "        if training:\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "        total_loss += loss.item() * y.size(0)\n",
    "        y_true.extend(y.cpu())\n",
    "        y_pred.extend(out.argmax(1).cpu())\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
    "    return total_loss / len(loader.dataset), acc, f1\n",
    "\n",
    "\n",
    "def main():\n",
    "    train_loader, test_loader = get_loaders()\n",
    "    net = CRNN().to(DEVICE)\n",
    "    opt = torch.optim.Adam(net.parameters(), lr=LR)\n",
    "    best = 0.0\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        _, tr_acc, tr_f1 = run_epoch(net, train_loader, opt)\n",
    "        _, te_acc, te_f1 = run_epoch(net, test_loader)\n",
    "        print(\n",
    "            f\"ep{epoch:02d}  train {tr_acc:.3f}/{tr_f1:.3f}  \"\n",
    "            f\"test {te_acc:.3f}/{te_f1:.3f}\"\n",
    "        )\n",
    "        if te_f1 > best:\n",
    "            best = te_f1\n",
    "            torch.save(net.state_dict(), \"best_crnn.pt\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
